{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. 训练一个神经网络\n",
    "\n",
    "上一节主要讲了简单的神经网络的结构，里面的参数$W$我们假定是已经训练好的。这一节我们要详细展开讨论一个神经网络是怎么训练的。\n",
    "\n",
    "如上一节所描述的，一个神经网络可以把一个任意维度的向量转变成另外一个任意维度的向量。一个能满足我们需要的神经网络需要把一个向量转变成另外一个“正确”的向量，而不是包含某些随意数值的向量。什么是“正确”呢？“正确”与否以我们给神经网络提供的“答案”为准。\n",
    "\n",
    "比如我们有一个向量$X_1$，它需要被转换成$Y_1$，那$Y_1$就是$X_1$的正确答案。\n",
    "\n",
    "然后我们有一堆的$X$，对应一堆的$Y$，就形成了一组训练样本。神经网络训练的目标就是准确地根据输入$X$预测应该输出的$Y$.\n",
    "\n",
    "刚开始训练的时候神经网络的$W$是随机初始化的，不能准确地根据输入$X$预测输出$Y$。但是它还是可以预测一个$\\hat{Y}$，然后我们就可以根据$Y$和$\\hat{Y}$的差距去调整$W$，直到$W$可以准确地根据$X$预测$Y$为止.\n",
    "\n",
    "当然，这里面 “根据差距去调整”涉及到一系列的操作，它们也是反向传导算法（BP算法）的关键。\n",
    "\n",
    "下面我们分几个小节来讨论，分别涉及到 误差函数， 偏导数， 链式法则 等技术细节。\n",
    "\n",
    "### 2.1 误差\n",
    "\n",
    "如上面所说，我们需要“根据差距去调整” $W$， 那我们首先要找到方法计算“差距”，准确说就是“误差”, 对应的英文是lost，计算这个误差的函数就是误差函数，也就是lost function.\n",
    "\n",
    "找到合适的误差函数以后，我们要做的就是让误差函数的输出尽可能小，就意味着“差距”变得最小，那就意味着我们的输出$\\hat{Y}$最接近真实值$Y$\n",
    "\n",
    "根据以上的描述，我们也可以直观地对误差函数提出几个要求，第一，误差函数的输出应该都是正数，因为比目标大也是“差距”，比目标小也是“差距”，标记“正差距”和“负差距”意义不大。 第二，误差函数的输出的最小值应该是0，就是预测值和真实值完全相同。\n",
    "\n",
    "根据以上直观形成的要求，第一个合适的误差函数应该是$Y$和$\\hat{Y}的差值的$绝对值，就是$|Y - \\hat{Y}|$。\n",
    "\n",
    "但是因为绝对值函数在零点处不可导，数学上不好处理，所以大家开始尝试其它误差函数，进一步尝试的误差函数就是平方差误差。\n",
    "\n",
    "此前我们都没有讨论过导数这个概念，为了让大家更好地理解后续的内容，我们先简单了解一下导数的概念。然后我们再来深入讨论其它的误差函数\n",
    "\n",
    "#### 2.1.1 导数\n",
    "\n",
    "\n",
    "导数是微积分学中一个非常重要的概念。它描述了函数在某一点的变化率,即函数在该点的切线斜率。导数可以帮助我们了解函数的变化趋势,并且在优化问题中扮演着关键的角色。\n",
    "\n",
    "对于一个函数 $f(x)$,它在点 $x$ 处的导数记作 $f'(x)$ 或 $\\frac{df}{dx}$,定义为:\n",
    "\n",
    "$$f'(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x}$$\n",
    "\n",
    "这个定义描述了导数的本质:它是函数在某一点的瞬时变化率。具体来说,它是函数在该点处的切线的斜率。\n",
    "\n",
    "让我们通过一些简单的例子来理解导数的概念:\n",
    "\n",
    "1. **一次函数**\n",
    "\n",
    "   考虑函数 $f(x) = 2x + 1$,它的导数为:\n",
    "   $$f'(x) = \\frac{d}{dx}(2x + 1) = 2$$\n",
    "   \n",
    "   这说明一次函数的导数是一个常数,即它在任何点处的切线斜率都是相同的。\n",
    "\n",
    "2. **二次函数**\n",
    "\n",
    "   考虑函数 $f(x) = x^2$,它的导数为:\n",
    "   $$f'(x) = \\frac{d}{dx}(x^2) = 2x$$\n",
    "   \n",
    "   这意味着二次函数在不同点处的切线斜率是不同的。例如,在点 $x=1$ 处,切线斜率为 $f'(1) = 2$;在点 $x=2$ 处,切线斜率为 $f'(2) = 4$。\n",
    "\n",
    "通过上面的例子,我们可以直观地理解导数就是函数在某一点处的切线斜率。导数不仅能描述函数的变化趋势,而且在优化问题中扮演着关键的角色。在后面的内容中,我们将看到如何利用导数来优化神经网络的参数。\n",
    "\n",
    "非常好的补充说明。确实,绝对值函数在0处不可导,这给将其作为误差函数时的数学处理带来了麻烦。\n",
    "\n",
    "绝对值函数 $f(x) = |x|$ 在 $x=0$ 处不可导的原因是,在该点左右两侧,函数的斜率是不同的。具体来说:\n",
    "\n",
    "- 当 $x>0$ 时,绝对值函数的斜率为1:\n",
    "  $$\\lim_{\\Delta x \\rightarrow 0^+} \\frac{|x+\\Delta x| - |x|}{\\Delta x} = 1$$\n",
    "  \n",
    "- 当 $x<0$ 时,绝对值函数的斜率为-1:\n",
    "  $$\\lim_{\\Delta x \\rightarrow 0^-} \\frac{|x+\\Delta x| - |x|}{\\Delta x} = -1$$\n",
    "\n",
    "因此,在 $x=0$ 处,左右两侧的极限不相等,根据导数的定义,绝对值函数在该点处是不可导的。\n",
    "\n",
    "这给将绝对值函数作为误差函数时的数学处理带来了麻烦,因为在优化过程中,我们需要计算误差函数关于网络参数的导数(梯度),而绝对值函数在0处的不可导性会使梯度计算变得复杂或不可能。\n",
    "\n",
    "因此,虽然绝对值函数直观上看似是一个合适的误差函数选择,但由于其不可导性,实际应用中人们通常会选择其他可导的函数作为误差函数,例如平方误差函数等。这些函数在所有点处都可导,从而可以简化梯度的计算,使得优化过程更加高效。\n",
    "\n",
    "\n",
    "\n",
    "#### 2.1.2 **平方差误差 (Squared Error, MSE)**\n",
    "\n",
    "平方差误差就是对$y$和$\\hat{y}$的差值求平方，这样就满足了之前提出的两个要求，一个是要求输出是正数，第二是要求最小值是0. \n",
    "\n",
    "平方差误差可以表示为:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{SE} = (y - \\hat{y})^2\n",
    "\\end{align}\n",
    "\n",
    "$y$ 是样本的真实值, $\\hat{y}$ 是样本的预测值。\n",
    "\n",
    "\n",
    "#### 2.1.3 **均方误差 (Mean Squared Error, MSE)**\n",
    "\n",
    "因为我们经常一个批次的样本，所以我们希望对一个批次的预测误差进行统一的计算，于是就有了均方差。\n",
    "\n",
    "均方差的思路很简单，就是每个样本单独求平方差，然后求一个批次内所有样本平方差的均值，就是加起来除于n,n是一个批次的样本数量\n",
    "\n",
    "均方误差可以表示为:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "\\end{align}\n",
    "\n",
    "其中 $n$ 是样本数量, $y_i$ 是第 $i$ 个样本的真实值, $\\hat{y}_i$ 是第 $i$ 个样本的预测值。\n",
    "\n",
    "举个例子,假设我们有一个回归问题,需要预测一个连续的数值。我们训练了一个神经网络模型,对于一个包含 5 个样本的数据集,真实值分别为 [3, 5, 2, 7, 4],而模型预测的值分别为 [2.8, 4.9, 2.2, 6.8, 4.1]。那么,这个模型在该数据集上的均方误差为:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{MSE} = \\frac{1}{5}[(3 - 2.8)^2 + (5 - 4.9)^2 + (2 - 2.2)^2 + (7 - 6.8)^2 + (4 - 4.1)^2] = 0.14\n",
    "\\end{align}\n",
    "\n",
    "我们希望最小化这个均方误差,使模型的预测值尽可能接近真实值。\n",
    "\n",
    "#### 2.1.4 **交叉熵损失 (Cross-Entropy Loss)**\n",
    "\n",
    "很多神经网络的输出最后都是一个概率分布，比如检测数字的神经网络的输出就是一个10维的向量，每个维度的值代表了对应数字的概率。\n",
    "\n",
    "比如，输出了一个这样的向量\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y}^T = \\begin{bmatrix} 0.05, 0.1, 0.2, 0.05, 0.15, 0.05, 0.1, 0.05, 0.2, 0.05 \\end{bmatrix}\n",
    "\n",
    "\\end{align}\n",
    "\n",
    "在这个向量中,每个元素代表了对应数字的概率。例如,第一个元素0.05代表了数字0的概率为5%,第三个元素0.2代表了数字2的概率为20%,以此类推。这个向量的所有元素之和为1,符合概率分布的要求。\n",
    "\n",
    "然后我们会拿这个输出和标记的“真实”值进行比较，以计算误差，比如对应的标记是这个数字其实是 2， 那标记的概率分布是这样的：\n",
    "\n",
    "\\begin{align}\n",
    "y^T = \\begin{bmatrix} 0, 0, 1, 0, 0, 0, 0, 0, 0, 0 \\end{bmatrix}\n",
    "\n",
    "\\end{align}\n",
    "\n",
    "这个时候使用均方差MSE就会有问题，因为除了2那个位置的1以外，其它概率都是0.也就是说我们的标记说这个数字是2，不是其它数字，但是我们的标记数据并不会说明这个字有多像其它数字。 标记数据其实并不是“真实”的概率分布，标记数据只是表明当前的样本的结果是什么。\n",
    "\n",
    "从计算结果上来看，就会导致预测的分布最终会向0概率趋近，神经网络在训练过程中会发现把所有值都预测成一个接近0的概率会得到最小的误差。\n",
    "\n",
    "为了解决这个问题，人们采用了交叉熵损失函数。\n",
    "\n",
    "交叉熵损失常用于分类问题,它度量了预测概率分布与真实概率分布之间的差异。对于一个样本,交叉熵损失可以表示为:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{CE} = -\\sum_{i=1}^{C}y_i\\log(\\hat{y}_i)\n",
    "\\end{align}\n",
    "\n",
    "其中 $C$ 是类别数量, $y_i$ 是第 $i$ 类的真实标签 (0 或 1), $\\hat{y}_i$ 是第 $i$ 类的预测概率。\n",
    "\n",
    "假设我们有一个二分类问题,需要判断一个图像是猫还是狗。我们训练了一个神经网络模型,对于一个真实标签为\"狗\"的图像,模型预测的概率分布为 [0.2, 0.8],其中 0.2 对应\"猫\"的概率,0.8 对应\"狗\"的概率。那么,这个样本的交叉熵损失为:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{CE} = -(0 \\log(0.2) + 1 \\log(0.8)) = 0.223\n",
    "\\end{align}\n",
    "\n",
    "我们希望最小化这个交叉熵损失,使模型的预测概率分布尽可能接近真实分布。\n",
    "\n",
    "通过最小化这些目标函数,我们可以使神经网络的输出逐渐接近期望值。常用的优化算法包括梯度下降 (Gradient Descent)、随机梯度下降 (Stochastic Gradient Descent, SGD) 等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbbf90a77c0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 以下是一个二分类问题的熵函数，其中p是正类的概率，1-p是负类的概率，H是熵值。\n",
    "# 真实概率分布是p=0.75，1-p=0.25。\n",
    "# 图中展示了当p在0.01到0.99之间变化时，熵值的变化情况。\n",
    "# 可以看到，当p=0.75时，熵值最小，交叉熵损失也最小。\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = np.arange(0.01, 0.99, 0.01)\n",
    "entropy = -np.log(p)*0.75 - np.log(1-p)*0.25\n",
    "\n",
    "plt.plot(p, entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 反向传播\n",
    "\n",
    "反向传播 (Backpropagation) 是训练多层神经网络的核心算法,它通过链式法则计算每个权重对误差的贡献,从而确定梯度方向,指导权重的调整。\n",
    "\n",
    "具体来说,反向传播算法包括以下步骤:\n",
    "\n",
    "1. **前向传播**: 输入样本通过神经网络层层传递,计算每一层的输出。\n",
    "2. **计算输出层误差**: 将输出层的输出与真实标签进行比较,计算输出层的误差。\n",
    "3. **反向传播误差**: 根据链式法则,将输出层的误差反向传播到前一层,计算每一层的误差。\n",
    "4. **计算梯度**: 对每一层的权重和偏置计算梯度,即它们对误差的偏导数。\n",
    "5. **更新权重和偏置**: 根据梯度的方向,使用优化算法 (如梯度下降) 更新权重和偏置。\n",
    "\n",
    "反向传播算法使得深层神经网络可以被有效地训练,因为它提供了一种端到端的误差传递机制,使得每一层的参数都可以根据最终的输出误差进行调整。\n",
    "\n",
    "从直观的角度进行拆解，根据误差计算参数的调整方向有两个关键技术点要解决，一个是同一层的神经网络中各个参数之间分别应该承担多少调整量，这个问题通过偏导数来解决； 第二个是不同层之间怎么传导误差，这个技术问题通过链式法则来解决。\n",
    "\n",
    "我们先用一个简单的神经网络来理解这两个关键技术点，然后再针对偏导数和链式法则做深入的讨论。\n",
    "\n",
    "假设我们有一个两层的神经网络，输入只有两个特征，就是$x_1$和$x_2$， 中间层有两个神经元，为了讨论方便用$h_1$和$h_2$来表示，然后$h_1$和$h_2$连接到最后一个输出层$y$。\n",
    "\n",
    "神经网络示意图如下：\n",
    "\n",
    "<div style=\"align-items: center;\">\n",
    "    <img src=\"../images/001_network.png\" alt=\"神经网络\" style=\"max-height:300px;background-color:#333333;\">\n",
    "</div>\n",
    "\n",
    "对应的数学表达如下：\n",
    "\n",
    "\n",
    "$$h_1 = w_1x_1 + w_2x_2 + b_1$$\n",
    "$$h_2 = w_3x_1 + w_4x_2 + b_2$$ \n",
    "$$y = w_5h_1 + w_6h_2 + b_3$$\n",
    "\n",
    "其中 $w_i$ 表示权重参数, $b_i$ 表示偏置参数。\n",
    "\n",
    "现在让我们从偏导数的角度来看,如何解决同一层参数之间的误差分担问题。以输出层为例,我们的目标是最小化均方误差损失函数:\n",
    "\n",
    "$$J(w, b) = \\frac{1}{2}(y - \\hat{y})^2$$\n",
    "\n",
    "其中 $\\hat{y}$ 是神经网络的输出,而 $y$ 是真实标签。为了更新参数,我们需要计算参数对误差的偏导数。对于输出层的权重 $w_5$,我们有:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_5} = \\frac{\\partial J}{\\partial y} \\cdot \\frac{\\partial y}{\\partial w_5} = (y - \\hat{y}) \\cdot h_1$$\n",
    "\n",
    "类似地,对于 $w_6$ 和 $b_3$,我们有:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_6} = (y - \\hat{y}) \\cdot h_2$$\n",
    "$$\\frac{\\partial J}{\\partial b_3} = y - \\hat{y}$$\n",
    "\n",
    "通过计算这些偏导数,我们可以确定每个参数应该如何调整,以减小总体误差。注意,同一层的不同参数对误差的贡献是不同的,这就是通过偏导数来分担误差的原因。\n",
    "\n",
    "接下来,让我们看看如何使用链式法则在不同层之间传播误差。我们从输出层开始,计算输出层误差对隐藏层输出的偏导数:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial h_1} = \\frac{\\partial J}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h_1} = (y - \\hat{y}) \\cdot w_5$$\n",
    "$$\\frac{\\partial J}{\\partial h_2} = \\frac{\\partial J}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h_2} = (y - \\hat{y}) \\cdot w_6$$\n",
    "\n",
    "现在,我们可以继续向后传播误差,计算隐藏层误差对输入层的偏导数:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial x_1} = \\frac{\\partial J}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial x_1} + \\frac{\\partial J}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial x_1} = (y - \\hat{y}) \\cdot (w_5w_1 + w_6w_3)$$\n",
    "$$\\frac{\\partial J}{\\partial x_2} = \\frac{\\partial J}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial x_2} + \\frac{\\partial J}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial x_2} = (y - \\hat{y}) \\cdot (w_5w_2 + w_6w_4)$$\n",
    "\n",
    "这里要注意，因为$x_1$和$x_2$已经是神经网络的输入，我们并不能改变它们，所以计算了它们的偏导数并不能指导我们如何调整第一层的参数。\n",
    "\n",
    "为了要知道第一层的参数分别需要调整多少，我们需要计算的其实是第一层参数$w_1, w_2, w_3, w_4$的偏导数。\n",
    "\n",
    "根据相同的方法，我们可以推导出:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_1} = \\frac{\\partial J}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial w_1} = (y - \\hat{y}) \\cdot w_5 \\cdot x_1$$\n",
    "$$\\frac{\\partial J}{\\partial w_2} = \\frac{\\partial J}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial w_2} = (y - \\hat{y}) \\cdot w_5 \\cdot x_2$$\n",
    "$$\\frac{\\partial J}{\\partial w_3} = \\frac{\\partial J}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial w_3} = (y - \\hat{y}) \\cdot w_6 \\cdot x_1$$\n",
    "$$\\frac{\\partial J}{\\partial w_4} = \\frac{\\partial J}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial w_4} = (y - \\hat{y}) \\cdot w_6 \\cdot x_2$$\n",
    "\n",
    "通过计算这些偏导数,我们可以获得第一层权重对最终误差的贡献,并相应地更新它们。\n",
    "\n",
    "例如,假设 $y = 1, \\hat{y} = 0.6, w_5 = 0.3, w_6 = 0.5, x_1 = 0.5, x_2 = 0.1$,我们可以计算:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w_1} = (1 - 0.6) \\cdot 0.3 \\cdot 0.5 = 0.06$$\n",
    "$$\\frac{\\partial J}{\\partial w_2} = (1 - 0.6) \\cdot 0.3 \\cdot 0.1 = 0.012$$\n",
    "$$\\frac{\\partial J}{\\partial w_3} = (1 - 0.6) \\cdot 0.5 \\cdot 0.5 = 0.1$$\n",
    "$$\\frac{\\partial J}{\\partial w_4} = (1 - 0.6) \\cdot 0.5 \\cdot 0.1 = 0.02$$\n",
    "\n",
    "根据这些梯度值,我们可以相应地更新第一层的权重参数。通过计算每个参数的梯度,反向传播算法可以有效地训练整个神经网络。\n",
    "\n",
    "通过这种方式,我们可以计算出每个参数对最终误差的贡献,并相应地更新它们。反向传播算法通过链式法则和偏导数,提供了一种高效的方法来训练深层神经网络。\n",
    "\n",
    "\n",
    "通过对以上数值的观察，我们可以看到第一层的参数对应要调整的数值已经比较小了，因为里面涉及到多个小数的乘法，当神经网络的层数变多以后，这个现象就会变得更加明显，直到这个数值小到我们的机器无法表达，这个现象就是梯度消失。\n",
    "\n",
    "另一方面，如果各个相乘的数都大于1，也有可能这个数值会变得很大很大，直到我们的机器无法表达为止，这个就是梯度爆炸。\n",
    "\n",
    "现实情况中梯度消失比较容易出现。不过，不管是梯度消失还是梯度爆炸，都给神经网络设计带来了一个很大的问题。\n",
    "\n",
    "下面我们稍微详细地展开讨论一下梯度消失和梯度爆炸：\n",
    "\n",
    "### 2.3 梯度消失和梯度爆炸\n",
    "\n",
    "\n",
    "\n",
    "#### 2.3.1 梯度消失\n",
    "\n",
    "梯度消失是指在训练深层神经网络时,由于反向传播过程中的链式求导运算,导致梯度值越来越小,最终接近于0的现象。这种现象会导致神经网络的权重无法正常更新,从而影响模型的训练效果。\n",
    "\n",
    "梯度消失的主要原因是在反向传播过程中,误差梯度通过激活函数的求导运算会被压缩,尤其是在使用sigmoid或tanh等饱和型激活函数时,梯度值在经过多层网络后会指数级衰减。具体来说,如果激活函数的导数值在(0,1)区间内,那么经过多层网络后,梯度将趋近于0。\n",
    "\n",
    "梯度消失会导致以下问题:\n",
    "\n",
    "1. **权重无法更新**:由于梯度接近于0,网络的权重无法正确地更新,模型无法继续学习。\n",
    "2. **信息无法有效传递**:梯度消失阻碍了信息在网络层之间的有效传递,网络难以学习到输入和输出之间的映射关系。\n",
    "3. **训练停滞**:由于权重无法更新,模型的训练过程会停滞,无法继续优化。\n",
    "\n",
    "为了缓解梯度消失的问题,研究人员提出了多种解决方案,例如:\n",
    "\n",
    "1. **使用ReLU激活函数**:ReLU激活函数的导数在正区间为1,避免了梯度消失的问题。但是ReLU也存在\"死亡神经元\"的缺陷。\n",
    "2. **残差连接(Residual Connection)**:残差连接通过直接将前面层的输出与后面层的输出相加,有效地缓解了梯度消失问题。\n",
    "3. **长短期记忆网络(LSTM)**:LSTM通过门控机制和记忆单元,可以更好地捕捉长期依赖关系,从而缓解梯度消失问题。\n",
    "4. **初始化技术**:合理的参数初始化方式,如Xavier初始化或He初始化,可以一定程度上缓解梯度消失问题。\n",
    "\n",
    "总的来说,梯度消失是训练深层神经网络时面临的一个重要挑战,需要通过合理的网络设计和优化技术来缓解。\n",
    "\n",
    "#### 2.3.2 梯度爆炸\n",
    "\n",
    "与梯度消失相反,梯度爆炸是指在反向传播过程中,梯度值会越来越大,最终超出计算机的表示范围的现象。梯度爆炸会导致模型的权重发散,无法收敛到最优解。\n",
    "\n",
    "梯度爆炸的主要原因是在反向传播过程中,误差梯度通过激活函数的求导运算会被放大,尤其是在使用ReLU等非饱和型激活函数时,梯度值在经过多层网络后会指数级增长。\n",
    "\n",
    "梯度爆炸会导致以下问题:\n",
    "\n",
    "1. **权重发散**:由于梯度过大,网络的权重会不断增大,远离最优解。\n",
    "2. **计算溢出**:当梯度值超出计算机的表示范围时,会导致计算溢出错误。\n",
    "3. **训练失败**:由于权重发散和计算溢出,模型的训练过程会失败,无法收敛。\n",
    "\n",
    "为了缓解梯度爆炸的问题,研究人员提出了以下解决方案:\n",
    "\n",
    "1. **梯度裁剪(Gradient Clipping)**:将梯度值限制在一个合理的范围内,避免梯度过大。\n",
    "2. **权重正则化**:通过L1或L2正则化项,限制权重的大小,防止权重过度增长。\n",
    "3. **梯度归一化(Gradient Normalization)**:将梯度向量归一化到单位范数,避免梯度过大。\n",
    "4. **初始化技术**:合理的参数初始化方式,如Xavier初始化或He初始化,可以一定程度上缓解梯度爆炸问题。\n",
    "\n",
    "总的来说,梯度爆炸是训练深层神经网络时面临的另一个重要挑战,需要通过合理的网络设计和优化技术来缓解。梯度爆炸和梯度消失都会影响模型的训练效果,因此需要格外注意。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
